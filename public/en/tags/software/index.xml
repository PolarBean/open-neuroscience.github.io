<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Software | Open Neuroscience</title>
    <link>https://open-neuroscience.com/en/tags/software/</link>
      <atom:link href="https://open-neuroscience.com/en/tags/software/index.xml" rel="self" type="application/rss+xml" />
    <description>Software</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 22 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://open-neuroscience.com/images/icon_hu98f7bdece981985d79e430785ac9bc37_26395_512x512_fill_lanczos_center_2.png</url>
      <title>Software</title>
      <link>https://open-neuroscience.com/en/tags/software/</link>
    </image>
    
    <item>
      <title>3D Slicer</title>
      <link>https://open-neuroscience.com/en/post/3d_slicer/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/3d_slicer/</guid>
      <description>&lt;p&gt;3D Slicer is a software for medical image informatics, image processing, and three-dimensional visualization. It’s extremely powerful and versatile with plenty of different options. It is a great tool for volume rendering, registration, interactive segmentation of images and even offers the possibility of running Python scripts thought an embedded Python interpreter.&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Ron Kikinis&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Slicer/Slicer&#34;&gt;https://github.com/Slicer/Slicer&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Miguel Fernandes&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>UC2</title>
      <link>https://open-neuroscience.com/en/post/uc2/</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/uc2/</guid>
      <description>&lt;p&gt;The open-source optical toolbox UC2 [YouSeeToo] simplifies the process of building optical setups, by combining 3D-printed cubes, each holding a specific component (e.g. lens, mirror) on a magnetic square-grid baseplate. The use of widely available consumables and 3D printing, together with documentation and software, offers an extremely low-cost and accessible alternative for both education and research areas. In order to reduce the entry barrier, we provide a fully comprehensive toolbox called TheBOX. A paper describing the scientific application in detail can be found 
&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2020.03.02.973073v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Benedict Diederich; René Lachmann; Barbora Marsikova&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://useetoo.org&#34;&gt;https://useetoo.org&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-video&#34;&gt;Project Video&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ey4uEFEG6MY&#34;&gt;https://www.youtube.com/watch?v=ey4uEFEG6MY&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Andre M Chagas&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Colaboratory</title>
      <link>https://open-neuroscience.com/en/post/colaboratory/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/colaboratory/</guid>
      <description>&lt;p&gt;Colaboratory is a free Jupyter notebook environment that runs in the cloud. Your notebooks get stored on Google Drive. The great advantage is that you don’t have to install anything (however, for some features you need a Google account) on your system to use it. You can perform specific computations during data analysis with pre-installed Python libraries and gives you access to accelerated hardware for free (e.g. GPUs and TPUs).&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Google&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/notebooks/intro.ipynb&#34;&gt;https://colab.research.google.com/notebooks/intro.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Miguel Fernandes&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Suite2P</title>
      <link>https://open-neuroscience.com/en/post/suite2p/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/suite2p/</guid>
      <description>&lt;p&gt;Suite2P is a very modular imaging processing pipeline written in Python which allows you to perform registration of raw data movies, automatic cell detection, extraction of calcium traces and infers spike times. It is a very fast and accurate tool and can work on standard workstations. It also includes a visualization graphical user interface (GUI) that facilitates analysis and manual curation of the cell detection algorithm.&lt;/p&gt;
&lt;h2 id=&#34;project-authors&#34;&gt;Project Author(s)&lt;/h2&gt;
&lt;p&gt;Carsen Stringer and Marius Pachitariu&lt;/p&gt;
&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://mouseland.github.io/suite2p/_build/html/index.html&#34;&gt;https://mouseland.github.io/suite2p/_build/html/index.html&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This post was automatically generated by
Miguel Fernandes&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Psychophysics toolboxes</title>
      <link>https://open-neuroscience.com/en/post/psychophysics-toolboxes/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/psychophysics-toolboxes/</guid>
      <description>&lt;br&gt;
&lt;p&gt;Roughly put, 
&lt;a href=&#34;http://en.wikipedia.org/wiki/Psychophysics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;psychophysics&lt;/a&gt; studies the relationships of physical stimuli and their respective elicited sensations and perception. Psyhophysics also relates to the techniques used to probe these relationships and the toolboxes here presented are mainly dealing with these techniques.&lt;/p&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/smathot/osdoc/3.2/themes/cogsci/static/img/banner.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;a href=&#34;https://osdoc.cogsci.nl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; OpenSesame&lt;/a&gt; is a graphical opensource experiment builder. It has drag and drop features as well as customization possibilities, via python scripting and custom plugins. here is a 
&lt;a href=&#34;http://link.springer.com/article/10.3758%2Fs13428-011-0168-7&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt; to a paper describing the software&lt;figure style=&#34;width: 853px&#34; class=&#34;wp-caption alignnone&#34;&gt;&lt;/p&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;p&gt;
&lt;a href=&#34;http://psychtoolbox.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Psychtoolbox&lt;/a&gt;, or PTB, is a free versatile toolbox to be used mainly in visual experiments, it is able to deliver visual and auditory stimuli and to receive subject input. It has a big quantity of active users (15,000 as stated on their 
&lt;a href=&#34;http://psychtoolbox.org/forum/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;) what should make the life of the beginner user somehow easier (they have a 
&lt;a href=&#34;https://psychtoolbox.discourse.group/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;forum page&lt;/a&gt;) The latest version (PTB-3 as this page was written) is able to run under MATLAB (version 7.X) and Octave (version 3.2.X) in any of the three main operational systems out there (Mac, Windows and Linux).  A paper describing the toolbox can be found 
&lt;a href=&#34;http://color.psych.upenn.edu/brainard/papers/Psychtoolbox.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;./psychopyLogoOnline.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.psychopy.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PsychoPy&lt;/a&gt; is also a free toolbox that can be used to deliver visual and auditory stimuli and receive inputs from subjects, on top of keyboard, mouse and button boxes, it also supports serial and parallel ports and compiled drivers (allowing interface with pretty much any hardware installed in your computer). It is written in Python, and it can be used with Windows, Mac or Linux. Two papers describing the toolbox can be found 
&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0165027006005772&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; and 
&lt;a href=&#34;https://www.frontiersin.org/articles/10.3389/neuro.11.010.2008/full&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python, NumPy, SciPy &amp; Matplotlib</title>
      <link>https://open-neuroscience.com/en/post/python-numpy-scipy-matplotlib/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/python-numpy-scipy-matplotlib/</guid>
      <description>&lt;p&gt;Python is a free programming language that is widely used, most of the software developed for Linux is written in Python. It contains several libraries that cover a lot of problem domains, from asynchronous processing to zip files. Also it is available for most platforms. More information can be found at the language 
&lt;a href=&#34;http://www.python.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;official page.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More specifically to scientific computation, the 
&lt;a href=&#34;http://www.numpy.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NumPy&lt;/a&gt; project brings n-dimension array objects, random number capabilities, fourier transforms and many other useful tools.&lt;/p&gt;
&lt;p&gt;Boosting NumPy capabilities is 
&lt;a href=&#34;http://www.scipy.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SciPy&lt;/a&gt;, which is another Python library that adds signal processing, optimization and statistical tools to Python.&lt;/p&gt;
&lt;p&gt;After all the calculations are done, they can be plotted also using python and another useful library: 
&lt;a href=&#34;http://matplotlib.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matplotlib.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spike Gadgets</title>
      <link>https://open-neuroscience.com/en/post/spike-gadgets/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/spike-gadgets/</guid>
      <description>&lt;p&gt;A brief description of their current software (09.Sep.2016) is provided by one of their founders, Mattias Karlsson:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;
&lt;a href=&#34;http://www.spikegadgets.com/software/statescript.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;State Script:&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Do you need to control lasers for optogenetics, stimulators, or other TTL-based devices with precise, temporally defined patterns? Do you need to monitor beam breaks, lever presses, or other digital events in real time to define behavioral tasks?  You could program an Arduino, but that’s a lot of work. Or, you can use StateScript, which allows users with minimal programming experience define complex input/output relationships for the most demanding hardware control experiments.&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;This open-source project now runs on two available hardware platforms, the MBED LPC1768 micro controller board ($50) and the SpikeGadgets electrophysiology and behavioral control system.  More hardware support in is the works. A software interface, which is part of the Trodes open-source eletrophysiology suite (&lt;a href=&#34;http://www.spikegadgets.com/software/trodes.html&#34; target=&#34;_blank&#34;&gt;&lt;a href=&#34;http://www.spikegadgets.com/software/trodes.html&#34;&gt;http://www.spikegadgets.com/software/trodes.html&lt;/a&gt;&lt;/a&gt;), allows you to upload scripts and dynamically interact with variables and ports states.&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;Anyone is welome to contribute. Here is the 
&lt;a href=&#34;https://bitbucket.org/mkarlsso/statescript&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bitbucket repo.&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
  &lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://i2.wp.com/www.spikegadgets.com/images/statescript_screenshot_2.png?resize=800%2C571&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
  &lt;/div&gt;
&lt;div&gt;
&lt;p&gt;&lt;strong&gt;
&lt;a href=&#34;http://www.spikegadgets.com/software/trodes.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trodes:&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Trodes is a software suite with a focus on data acquisition for extracellular neural recordings.  It has a growing user base and welcomes contributors with open arms! It is built using the ever-popular and powerful Qt C++ framework. While it is specialized to be used with SpikeGadgets’ ephys hardware, it also has built-in support for the Intan demo system and Open-Ephys hardware.&lt;/p&gt;
&lt;p&gt;It has some pretty impressive capabilities, including visualization of thousands of channels, spike viewing, online spike sorting, and low latency feedback control.  It has video processing, allowing position tracking that is synchronized to the recording, and integrates powerful environment control (lasers for optogenetics, levers, lights, pumps, etc.) with StateScript.&lt;/p&gt;
&lt;/div&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://i1.wp.com/www.spikegadgets.com/images/trodesscreenshot.png?resize=800%2C444&#34; alt=&#34;Trodes interface&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt; Trodes interface &lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i1.wp.com/www.spikegadgets.com/images/trodes_screenshot_cameramod.png?resize=800%2C554&#34; alt=&#34;Trodes interface&#34;&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt; Trodes &lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Brainflow</title>
      <link>https://open-neuroscience.com/en/post/brainflow/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/brainflow/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://brainflow.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BrainFlow&lt;/a&gt; BrainFlow is a library intended to obtain, parse and analyze EEG, EMG, ECG and other kinds of data from biosensors, it provides two APIs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data Acquisition API to obtain data from BCI boards&lt;/li&gt;
&lt;li&gt;Signal Processing API which is completely independent and can be used without Data Acquisition API&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both of these APIs are uniform for all supported boards, so it allows to write completely board agnostic code.&lt;/p&gt;
&lt;p&gt;BrainFlow has bindings for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C++&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;li&gt;C#&lt;/li&gt;
&lt;li&gt;R&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And provides almost the same API for all languages above.&lt;/p&gt;
&lt;p&gt;Check 
&lt;a href=&#34;https://brainflow.readthedocs.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BrainFlow Docs&lt;/a&gt; for details.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image, Office suites, and other general purpose software</title>
      <link>https://open-neuroscience.com/en/post/image-office-suits-and-other-general-purpose-software/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/image-office-suits-and-other-general-purpose-software/</guid>
      <description>&lt;p&gt;If you are using Linux, changes are that this page is not that useful for you, since most of these programs come installed by default. For you who are not yet into linux, most of these programs have Windows/Mac versions:&lt;/p&gt;
&lt;p&gt;Office suites (spreadsheet calculation, slide manufacturing , document writing):&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.openoffice.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open Office&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.libreoffice.org/#0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Libre Office&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Image manipulation programs (vectorized images or photoshop style):&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://inkscape.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Inkscape&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.gimp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gimp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3D modelling (to create animations, solids or even things that can be printed):&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://free-cad.sourceforge.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FreeCad&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.blender.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blender&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.openscad.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenScad&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>IPipet</title>
      <link>https://open-neuroscience.com/en/post/ipipet/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/ipipet/</guid>
      <description>&lt;p&gt;IPipet is a neat system to help you not to lose track of which wells you have already pipetted in or from. The idea is simple, you place a tablet running a link with your specific pipetting protocol under your source and destination plates. The tablet will illuminate the corresponding wells. After you pipette one sample, you press next on the tablet and the next sample will be illuminated. For more details watch the video (below) and visit the 
&lt;a href=&#34;http://ipipet.teamerlich.org/usage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;project&amp;rsquo;s homepage.&lt;/a&gt; They even have a 
&lt;a href=&#34;http://www.thingiverse.com/thing:339588&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3D printable adaptor&lt;/a&gt; to prevent the well plate from slipping on the tablet surface.&lt;/p&gt;
&lt;br&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;iframe src=&#34;https://player.vimeo.com/video/90988265&#34; width=&#34;640&#34; height=&#34;360&#34; frameborder=&#34;0&#34; allow=&#34;autoplay; fullscreen&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://vimeo.com/90988265&#34;&gt;iPipet Demo&lt;/a&gt; from &lt;a href=&#34;https://vimeo.com/user26499168&#34;&gt;Team Erlich&lt;/a&gt; on &lt;a href=&#34;https://vimeo.com&#34;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Lab management software</title>
      <link>https://open-neuroscience.com/en/post/lab-management-software/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/lab-management-software/</guid>
      <description>&lt;p&gt;Since organisation of ideas, stocks, and projects is a major concern (or at least should be) of labs and researchers, here is a small compilation of cost free sofware to help out:&lt;/p&gt;
&lt;br&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;./Quartzy.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.quartzy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quartzy&lt;/a&gt; is a free web based application (supported by life sciences related companies) it focuses on sharing protocols, tracking orders, manage lab inventory and shared quipment management.&lt;/p&gt;
&lt;br&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;img src=&#34;./elabftw-logo.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.elabftw.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eLabFTW&lt;/a&gt; is a management system created by Nicolas Carpi. It is opensource (which means each lab can customize it for special needs), free and it can be installed locally. Its 
&lt;a href=&#34;https://demo.elabftw.net/login.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online demo version&lt;/a&gt; focuses on experiment log, database (where drugs, chemicals, animal strains and etc can be logged) and team (where lab members can be listed).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Operating systems</title>
      <link>https://open-neuroscience.com/en/post/linux-distributions/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/linux-distributions/</guid>
      <description>&lt;p&gt;Linux is an open source operating system and it is the major OS used in servers and supercomputers.  
&lt;a href=&#34;http://www.ubuntu.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ubuntu&lt;/a&gt;, one of the best known distributions has been gaining space in the personal computing scene, now days already being factory 
&lt;a href=&#34;http://www.omgubuntu.co.uk/2012/05/ubuntu-to-ship-on-5-of-all-pcs-sold-next-year&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shipped&lt;/a&gt; by major manufacturers.&lt;/p&gt;
&lt;p&gt;But how practical is to migrate to a Linux distribution? Well, very. If one passes beyond the hassle of backing up data and installing a new OS, there are many advantages that come with it. For starters these OSs are safer than any Microsoft or Apple OS. There is a large community of users sharing solutions to problems, bugs and so on (there hasn’t been to today a widespread of any 
&lt;a href=&#34;http://en.wikipedia.org/wiki/Linux_malware&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;malware through Linux systems&lt;/a&gt;). Being open source, the distributions are perfect for customization, something really useful for science labs.&lt;/p&gt;
&lt;p&gt;A Small list of distributions that make a good starting point:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://www.debian.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Debian&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://neuro.debian.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NeuroDebian&lt;/a&gt; (Debian oriented to neuroscience)&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;www.ubuntu.com&#34;&gt;Ubuntu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://www.linuxmint.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mint&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://en.opensuse.org/Main_Page&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenSuse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://fedoraproject.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fedora&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.ros.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ROS&lt;/a&gt; –&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The robot operating system is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Computer Vision and motion tracking software</title>
      <link>https://open-neuroscience.com/en/post/computer-vision-and-motion-tracking-software/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/computer-vision-and-motion-tracking-software/</guid>
      <description>&lt;p&gt;Motion tracking can be really useful in neurosciences, for automatic measurements of behaviour, among other things. Here you’ll find a small list of tracking softwares or libraries used to build such softwares:&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Complete softwares:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;http://ctrax.sourceforge.net/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ctrax&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;figure style=&#34;width: 128px&#34; class=&#34;wp-caption alignnone&#34;&gt;[&lt;img src=&#34;https://i0.wp.com/ctrax.sourceforge.net/images/ctrax-logo2b_128.png?resize=128%2C128&#34; alt=&#34;&#34; width=&#34;128&#34; height=&#34;128&#34; data-recalc-dims=&#34;1&#34; /&gt;](https://i0.wp.com/ctrax.sourceforge.net/images/ctrax-logo2b_128.png)&lt;figcaption class=&#34;wp-caption-text&#34;&gt;taken from: http://ctrax.sourceforge.net/index.html&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;Ctrax is an open-source, freely available, machine vision program for estimating the positions and orientations of many walking flies, maintaining their individual identities over long periods of time. It was designed to allow high-throughput, quantitative analysis of behavior in freely moving flies.&lt;/ul&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The bio tracking project, designed for multiple object tracking, developed at Georgia tech:&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bio-tracking.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;a href=&#34;http://www.bio-tracking.org/&#34;&gt;http://www.bio-tracking.org/&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;embed-youtube&#34; style=&#34;text-align:center; display: block;&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Community Core Vision: Built with computer vision and machine sensing in mind, they mention multi touch applications as one of their focus on the website.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ccv.nuigroup.com/&#34;&gt;http://ccv.nuigroup.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;embed-youtube&#34; style=&#34;text-align:center; display: block;&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://derek.simkowiak.net/motion-tracking-with-python/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Motion Tracking using python&lt;/a&gt;: Independent developed software by Derek Simkowiak, in a project he ran a couple of years back with his daughter, to track Gerbills&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;embed-youtube&#34; style=&#34;text-align:center; display: block;&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://personal.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tracking-Learning-Detection&lt;/a&gt;: Developed by 
&lt;a href=&#34;http://personal.ee.surrey.ac.uk/Personal/Z.Kalal/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zdenek Kalal&lt;/a&gt; this software intends to track pretty much anything (object determination can be done via mouse) in real time and to learn features from the object as tracking goes on.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;embed-youtube&#34; style=&#34;text-align:center; display: block;&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; 
&lt;a href=&#34;http://openvisionc.sourceforge.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open Vision Control&lt;/a&gt;: Developed on top of OpenCV (see below) in Python, it is a general purpose tracking software with several applications&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;embed-youtube&#34; style=&#34;text-align:center; display: block;&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SwisTrack: Developed at EPFL, it is also a tracking system for multiple objects&lt;figure id=&#34;attachment_744&#34; style=&#34;width: 300px&#34; class=&#34;wp-caption aligncenter&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
&lt;a href=&#34;https://i0.wp.com/openeuroscience.com/wp-content/uploads/2014/04/800px-swistrack4-ubuntu.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img class=&#34;size-medium wp-image-744&#34; src=&#34;https://i0.wp.com/openeuroscience.com/wp-content/uploads/2014/04/800px-swistrack4-ubuntu.png?resize=300%2C211&#34; alt=&#34;From http://en.wikibooks.org/wiki/Swistrack&#34; width=&#34;300&#34; height=&#34;211&#34; srcset=&#34;https://i0.wp.com/openeuroscience.com/wp-content/uploads/2014/04/800px-swistrack4-ubuntu.png?w=800 800w, https://i0.wp.com/openeuroscience.com/wp-content/uploads/2014/04/800px-swistrack4-ubuntu.png?resize=300%2C212 300w, https://i0.wp.com/openeuroscience.com/wp-content/uploads/2014/04/800px-swistrack4-ubuntu.png?resize=768%2C541 768w&#34; sizes=&#34;(max-width: 300px) 100vw, 300px&#34; data-recalc-dims=&#34;1&#34; /&gt;&lt;/a&gt;&lt;figcaption class=&#34;wp-caption-text&#34;&gt;From &lt;a href=&#34;http://en.wikibooks.org/wiki/Swistrack&#34;&gt;http://en.wikibooks.org/wiki/Swistrack&lt;/a&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://infoscience.epfl.ch/record/85929&#34;&gt;http://infoscience.epfl.ch/record/85929&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://infoscience.epfl.ch/record/125704&#34;&gt;http://infoscience.epfl.ch/record/125704&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0042247&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tracking software for Drosophila&lt;/a&gt;, by Colomb &lt;em&gt;et al&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computer vision/tracking libraries:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://opencv.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open CV&lt;/a&gt; is a library for machine learning and computer vision. It is written for different computer languages and different operational systems.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.simplecv.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simple CV&lt;/a&gt; is a framework that tries to simplify the development of software that require computer vision/machine learning, since a lot of researchers have the necessity of building on such concepts, but sometimes don’t have the time/training necessary to do so.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Python for Neurosciences (Frontiers collection)</title>
      <link>https://open-neuroscience.com/en/post/python-for-neuroscience-frontiers-collection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/python-for-neuroscience-frontiers-collection/</guid>
      <description>&lt;p&gt;Frontiers has created not one but two nice collections about open source software for neurosciences written in Python.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://journal.frontiersin.org/researchtopic/8/python-in-neuroscience&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Here is collection 1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://journal.frontiersin.org/researchtopic/1591/python-in-neuroscience-ii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Here is collection 2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In these collections the readers will find a lot of nice resources, ranging from stimulus generation, to data formatting and analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simulations</title>
      <link>https://open-neuroscience.com/en/post/simulation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/simulation/</guid>
      <description>&lt;div id=&#34;pl-1067&#34;  class=&#34;panel-layout&#34; &gt;
  &lt;div id=&#34;pg-1067-0&#34;  class=&#34;panel-grid panel-no-style&#34; &gt;
    &lt;div id=&#34;pgc-1067-0-0&#34;  class=&#34;panel-grid-cell&#34; &gt;
      &lt;div id=&#34;panel-1067-0-0-0&#34; class=&#34;so-panel widget widget_sow-editor panel-first-child panel-last-child&#34; data-index=&#34;0&#34; &gt;
        &lt;div class=&#34;so-widget-sow-editor so-widget-sow-editor-base&#34;&gt;
          &lt;div class=&#34;siteorigin-widget-tinymce textwidget&#34;&gt;
            &lt;p&gt;
              Ever thought about playing with a virtual worm? or interacting with a simulated bee brain? Sounds interesting no? These are just two projects that offer anyone the opportunity to play around with brain/neuronal simulations and models. Some of them are hardware based, and some completely software:
            &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        &amp;lt;p&amp;gt;
          &amp;lt;a href=&amp;quot;http://openeuroscience.com/open-source-simulations-and-models/open-worm/&amp;quot;&amp;gt;OpenWorm&amp;lt;/a&amp;gt;
        &amp;lt;/p&amp;gt;

        &amp;lt;p&amp;gt;
          &amp;lt;a href=&amp;quot;http://openeuroscience.com/open-source-simulations-and-models/green-brain/&amp;quot;&amp;gt;GreenBrain&amp;lt;/a&amp;gt;
        &amp;lt;/p&amp;gt;

        &amp;lt;p&amp;gt;
          &amp;lt;a href=&amp;quot;http://openeuroscience.com/open-source-simulations-and-models/neuronsneuronsneurons/&amp;quot;&amp;gt;Neurons,Neurons,Neurons&amp;lt;/a&amp;gt;
        &amp;lt;/p&amp;gt;

        &amp;lt;p&amp;gt;
          &amp;lt;a href=&amp;quot;http://openeuroscience.com/open-source-simulations-and-models/big-neuron/&amp;quot;&amp;gt;Big Neuron&amp;lt;/a&amp;gt;
        &amp;lt;/p&amp;gt;
      &amp;lt;/div&amp;gt;
    &amp;lt;/div&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;section class=&#34;blog&#34;&gt;
  &lt;div class=&#34;container&#34;&gt;
    &lt;div class=&#34;post-list&#34; itemscope=&#34;&#34; itemtype=&#34;http://schema.org/Blog&#34;&gt;
      {% for page in site.pages %}
        {% for category in page.categories %}
          {% if category == &#34;Simulation&#34; %}
            {% include card_page.html %}
          {% endif %}
        {% endfor %}
      {% endfor %}
&lt;pre&gt;&lt;code&gt;&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/div&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Vision Egg</title>
      <link>https://open-neuroscience.com/en/post/vision-egg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://open-neuroscience.com/en/post/vision-egg/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;http://visionegg.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vision Egg&lt;/a&gt; is a Python library for generating visual stimuli.&lt;/p&gt;
&lt;p&gt;In more detail, it is a high level interface in between Python and OpenGL, and can use inexpensive consumer grade graphics cards to generate precise visual stimuli. A paper with more details can be found here &lt;a href=&#34;http://journal.frontiersin.org/article/10.3389/neuro.11.004.2008/full&#34;&gt;http://journal.frontiersin.org/article/10.3389/neuro.11.004.2008/full&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
